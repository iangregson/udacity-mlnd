{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "Ian Gregson\n",
    "September 22nd 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load up our std libraries and start having some fun\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "%matplotlib inline\n",
    "\n",
    "# Set up some necessary constants\n",
    "SPLIT_RANDOM_SEED = 42\n",
    "DCLF_RANDOM_SEED = 42\n",
    "K_FOLD_RANDOM_SEED = 3\n",
    "K_FOLDS = 5\n",
    "K_FEATURES = 50\n",
    "NA_THRESHOLD = 0.975\n",
    "LABEL_COLUMN = 'StageName'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set up a scoring function that uses the f1 score metric\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "f1_scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set up the dummy classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dclf = DummyClassifier(random_state=DCLF_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean f1_score from KFold cross validation 0.59'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First up, load the raw dataset\n",
    "raw_data = pd.read_csv('data/csv/selected_columns.csv', low_memory=False)\n",
    "\n",
    "# Drop rows with labels that are not relevant and separate features from labels\n",
    "data = utils.drop_rows(raw_data)\n",
    "labels = utils.get_labels(data, label_column=LABEL_COLUMN)\n",
    "features = data.drop(columns=[LABEL_COLUMN], axis=1)\n",
    "\n",
    "# One hot encode categorical features\n",
    "features = utils.encode(features)\n",
    "\n",
    "# Drop null columns\n",
    "features = utils.drop_na_columns(features, label_column=LABEL_COLUMN, na_threshold=NA_THRESHOLD)\n",
    "\n",
    "# Drop correlated features\n",
    "features = utils.drop_corr_columns(features, labels)\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = utils.data_split(features, labels, random_state=SPLIT_RANDOM_SEED)\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "X_train = max_abs_scaler.fit_transform(X_train)\n",
    "X_test = max_abs_scaler.fit_transform(X_test)\n",
    "\n",
    "# Feature selection\n",
    "X_train = utils.feature_selection(X_train, y_train, K_FEATURES)\n",
    "X_test = utils.feature_selection(X_test, y_test, K_FEATURES)\n",
    "\n",
    "# Score the dummy classifier\n",
    "from sklearn import model_selection\n",
    "kfold = model_selection.KFold(n_splits=K_FOLDS, random_state=K_FOLD_RANDOM_SEED)\n",
    "cv_results = model_selection.cross_val_score(dclf, X_train, y_train, cv=kfold, scoring=f1_scorer)\n",
    "display('Mean f1_score from KFold cross validation {:0.2f}'.format(cv_results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('data/csv/processed_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DummyClassifier achieves an average of **f1 score** 59%. This establishes a baseline for assessing the success of the final modal. Given the dataset, a guess could be expected to be accurate in 59% of predictions. In order to demonstrate that the final model built in the project is better than a guess, it must a achieve a better average f1 score than 59%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.934842 (0.003276)\n",
      "NB: 0.897618 (0.017178)\n",
      "KNN: 0.942352 (0.005056)\n",
      "SVM: 0.914069 (0.003355)\n",
      "RF: 0.988457 (0.000680)\n",
      "LGBM: 0.990637 (0.000814)\n",
      "XGB: 0.990019 (0.001041)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preparing models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('LGBM', lgb.sklearn.LGBMClassifier(objective='binary')))\n",
    "models.append(('XGB', xgb.XGBClassifier()))\n",
    "\n",
    "# Model Evaluation\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=K_FOLDS, random_state=K_FOLD_RANDOM_SEED)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=f1_scorer)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# Boxplot to compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparison of Classification Algorithms')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 0.9872278664731496, 'tuned_model': 0.9861938671704693}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gridParams = {\n",
    "    'n_estimators': [50,100,150],\n",
    "    'num_leaves': [15,31,45,60],\n",
    "    'max_bin': [125,255,380],\n",
    "    'objective' : ['binary'],\n",
    "}\n",
    "\n",
    "model = lgb.sklearn.LGBMClassifier(objective='binary')\n",
    "tuned_model = GridSearchCV(model, gridParams,\n",
    "                    verbose=0,\n",
    "                    cv=4,\n",
    "                    n_jobs=2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "tuned_model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "tuned_y_pred = tuned_model.predict(X_test)\n",
    "\n",
    "scores = {\n",
    "    'model': f1_score(y_pred, y_test),\n",
    "    'tuned_model': f1_score(tuned_y_pred, y_test),\n",
    "}\n",
    "\n",
    "display(scores)\n",
    "\n",
    "# final_model = lgb.sklearn.LGBMClassifier(\n",
    "#     n_estimators=model.best_params_['n_estimators'],\n",
    "#     num_leaves=model.best_params_['num_leaves'],\n",
    "#     objective=model.best_params_['objective'],\n",
    "#     max_bin=model.best_params_['max_bin']\n",
    "# )\n",
    "# final_model.fit(X_train, y_train)\n",
    "# y_pred = final_model.predict(X_test)\n",
    "# score = f1_score(y_pred, y_test)\n",
    "# display(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will need to discuss the process of improvement you made upon the algorithms and techniques you used in your implementation. For example, adjusting parameters for certain models to acquire improved solutions would fall under the refinement category. Your initial and final solutions should be reported, as well as any significant intermediate results as necessary. Questions to ask yourself when writing this section:\n",
    "- _Has an initial solution been found and clearly reported?_\n",
    "- _Is the process of improvement clearly documented, such as what techniques were used?_\n",
    "- _Are intermediate and final solutions clearly reported as the process is improved?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the final model and any supporting qualities should be evaluated in detail. It should be clear how the final model was derived and why this model was chosen. In addition, some type of analysis should be used to validate the robustness of this model and its solution, such as manipulating the input data or environment to see how the model’s solution is affected (this is called sensitivity analysis). Questions to ask yourself when writing this section:\n",
    "- _Is the final model reasonable and aligning with solution expectations? Are the final parameters of the model appropriate?_\n",
    "- _Has the final model been tested with various inputs to evaluate whether the model generalizes well to unseen data?_\n",
    "- _Is the model robust enough for the problem? Do small perturbations (changes) in training data or the input space greatly affect the results?_\n",
    "- _Can results found from the model be trusted?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jusitifcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, your model’s final solution and its results should be compared to the benchmark you established earlier in the project using some type of statistical analysis. You should also justify whether these results and the solution are significant enough to have solved the problem posed in the project. Questions to ask yourself when writing this section:\n",
    "- _Are the final results found stronger than the benchmark result reported earlier?_\n",
    "- _Have you thoroughly analyzed and discussed the final solution?_\n",
    "- _Is the final solution significant enough to have solved the problem?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free-Form Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will need to provide some form of visualization that emphasizes an important quality about the project. It is much more free-form, but should reasonably support a significant result or characteristic about the problem that you want to discuss. Questions to ask yourself when writing this section:\n",
    "- _Have you visualized a relevant or important quality about the problem, dataset, input data, or results?_\n",
    "- _Is the visualization thoroughly analyzed and discussed?_\n",
    "- _If a plot is provided, are the axes, title, and datum clearly defined?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will summarize the entire end-to-end problem solution and discuss one or two particular aspects of the project you found interesting or difficult. You are expected to reflect on the project as a whole to show that you have a firm understanding of the entire process employed in your work. Questions to ask yourself when writing this section:\n",
    "- _Have you thoroughly summarized the entire process you used for this project?_\n",
    "- _Were there any interesting aspects of the project?_\n",
    "- _Were there any difficult aspects of the project?_\n",
    "- _Does the final model and solution fit your expectations for the problem, and should it be used in a general setting to solve these types of problems?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will need to provide discussion as to how one aspect of the implementation you designed could be improved. As an example, consider ways your implementation can be made more general, and what would need to be modified. You do not need to make this improvement, but the potential solutions resulting from these changes are considered and compared/contrasted to your current solution. Questions to ask yourself when writing this section:\n",
    "- _Are there further improvements that could be made on the algorithms or techniques you used in this project?_\n",
    "- _Were there algorithms or techniques you researched that you did not know how to implement, but would consider using if you knew how?_\n",
    "- _If you used your final solution as the new benchmark, do you think an even better solution exists?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------\n",
    "\n",
    "**Before submitting, ask yourself. . .**\n",
    "\n",
    "- Does the project report you’ve written follow a well-organized structure similar to that of the project template?\n",
    "- Is each section (particularly **Analysis** and **Methodology**) written in a clear, concise and specific fashion? Are there any ambiguous terms or phrases that need clarification?\n",
    "- Would the intended audience of your project be able to understand your analysis, methods, and results?\n",
    "- Have you properly proof-read your project report to assure there are minimal grammatical and spelling mistakes?\n",
    "- Are all the resources used for this project correctly cited and referenced?\n",
    "- Is the code that implements your solution easily readable and properly commented?\n",
    "- Does the code execute without error and produce results similar to those reported?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
